{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy_of_Word_Spelling_Correction_with_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqAOYBEvkBhy"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GGpPd6XkVC1",
        "outputId": "480f3fc1-d14f-49d8-bf10-a81907c43789"
      },
      "source": [
        "# File loading\n",
        "df  = pd.read_csv('/content/data_2.csv',encoding=\"utf-8\")\n",
        "print(df.shape)\n",
        "df.dropna(axis=0,how='any')\n",
        "print(df.shape)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(110144, 2)\n",
            "(110144, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tizRtgcKkWxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf748ca-62d5-48a4-825a-6bf9b78bfc04"
      },
      "source": [
        "lines = [x for x in df['word'] if type(x) == type('a') ]\n",
        "print(\"Line Count:\",len(lines))\n",
        "print(lines[:4])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Line Count: 110143\n",
            "['إلى', 'التعليق', 'رقم', '2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNW4xnDwkYr3"
      },
      "source": [
        "# Preprocessing\n",
        "import re\n",
        "def process(sent):\n",
        "    # sent=sent.lower()\n",
        "    # sent=re.sub(r'[^0-9]','',sent)\n",
        "    sent=sent.replace('\\n','')\n",
        "    sent=sent.replace('ـ','')\n",
        "    sent=sent.replace('-','')\n",
        "    sent=sent.replace(')','')\n",
        "    sent=sent.replace('(','')\n",
        "    sent=sent.replace('*','')\n",
        "    sent=sent.replace(',','،')\n",
        "    sent=sent.replace('/','')\n",
        "    sent=sent.replace('&','')\n",
        "    sent=sent.replace('amp','')\n",
        "    sent=sent.replace('_','')\n",
        "    sent=sent.replace('ّ','')\n",
        "    sent=sent.replace('ً','')\n",
        "    sent=sent.replace('%','')\n",
        "    sent=sent.replace(';','')\n",
        "\n",
        "\n",
        "\n",
        "    return sent   "
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxGJ4BT3kabl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1beeecbf-2919-4b66-bf21-4b1e0bfa4dc1"
      },
      "source": [
        "lines =[process(x) for x in lines]\n",
        "temp = []\n",
        "for line in lines:\n",
        "    temp+= [ x for x in line.split() ]\n",
        "lines = list(set(temp))\n",
        "print(\"\\n\".join(lines[:4]))\n",
        "print(\"Number of items:\",len(lines))"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "المجرميين\n",
            "مفحمة\n",
            "هائلة\n",
            "الحزين\n",
            "Number of items: 102677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuu-sVQtkb8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4124720-0ca6-4ef5-dc35-fb9b4bc59378"
      },
      "source": [
        "# CHAR INDEXING\n",
        "char_set = list('\"‘ی،.؟!يـابتةثجحخدذرزسشصضطظعغفقكلمنهوىيءآأؤإڕئک١٢٣٤٥٦٧٨٩٠0123456789')\n",
        "char2int = { char_set[x]:x for x in range(len(char_set)) }\n",
        "int2char = { char2int[x]:x for x in char_set }\n",
        "print(char2int)\n",
        "print(int2char)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\"': 0, '‘': 1, 'ی': 2, '،': 3, '.': 4, '؟': 5, '!': 6, 'ي': 38, 'ـ': 8, 'ا': 9, 'ب': 10, 'ت': 11, 'ة': 12, 'ث': 13, 'ج': 14, 'ح': 15, 'خ': 16, 'د': 17, 'ذ': 18, 'ر': 19, 'ز': 20, 'س': 21, 'ش': 22, 'ص': 23, 'ض': 24, 'ط': 25, 'ظ': 26, 'ع': 27, 'غ': 28, 'ف': 29, 'ق': 30, 'ك': 31, 'ل': 32, 'م': 33, 'ن': 34, 'ه': 35, 'و': 36, 'ى': 37, 'ء': 39, 'آ': 40, 'أ': 41, 'ؤ': 42, 'إ': 43, 'ڕ': 44, 'ئ': 45, 'ک': 46, '١': 47, '٢': 48, '٣': 49, '٤': 50, '٥': 51, '٦': 52, '٧': 53, '٨': 54, '٩': 55, '٠': 56, '0': 57, '1': 58, '2': 59, '3': 60, '4': 61, '5': 62, '6': 63, '7': 64, '8': 65, '9': 66}\n",
            "{0: '\"', 1: '‘', 2: 'ی', 3: '،', 4: '.', 5: '؟', 6: '!', 38: 'ي', 8: 'ـ', 9: 'ا', 10: 'ب', 11: 'ت', 12: 'ة', 13: 'ث', 14: 'ج', 15: 'ح', 16: 'خ', 17: 'د', 18: 'ذ', 19: 'ر', 20: 'ز', 21: 'س', 22: 'ش', 23: 'ص', 24: 'ض', 25: 'ط', 26: 'ظ', 27: 'ع', 28: 'غ', 29: 'ف', 30: 'ق', 31: 'ك', 32: 'ل', 33: 'م', 34: 'ن', 35: 'ه', 36: 'و', 37: 'ى', 39: 'ء', 40: 'آ', 41: 'أ', 42: 'ؤ', 43: 'إ', 44: 'ڕ', 45: 'ئ', 46: 'ک', 47: '١', 48: '٢', 49: '٣', 50: '٤', 51: '٥', 52: '٦', 53: '٧', 54: '٨', 55: '٩', 56: '٠', 57: '0', 58: '1', 59: '2', 60: '3', 61: '4', 62: '5', 63: '6', 64: '7', 65: '8', 66: '9'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqkwLkE2HIu7",
        "outputId": "bb84242e-2b9d-402a-bab2-cb45104ca9af"
      },
      "source": [
        "char2int['ی']"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfBn0BnOkdrj",
        "outputId": "94c8c14d-8c40-4599-ed22-723beeaed455"
      },
      "source": [
        "count = len(char_set)\n",
        "codes = [\"\\t\",\"\\n\",'#']\n",
        "for i in range(len(codes)):\n",
        "    code = codes[i] #i=0,code=\\t\n",
        "    char2int[code]=count\n",
        "    int2char[count]=code\n",
        "    count+=1\n",
        "print(char2int)\n",
        "print(int2char)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\"': 0, '‘': 1, 'ی': 2, '،': 3, '.': 4, '؟': 5, '!': 6, 'ي': 38, 'ـ': 8, 'ا': 9, 'ب': 10, 'ت': 11, 'ة': 12, 'ث': 13, 'ج': 14, 'ح': 15, 'خ': 16, 'د': 17, 'ذ': 18, 'ر': 19, 'ز': 20, 'س': 21, 'ش': 22, 'ص': 23, 'ض': 24, 'ط': 25, 'ظ': 26, 'ع': 27, 'غ': 28, 'ف': 29, 'ق': 30, 'ك': 31, 'ل': 32, 'م': 33, 'ن': 34, 'ه': 35, 'و': 36, 'ى': 37, 'ء': 39, 'آ': 40, 'أ': 41, 'ؤ': 42, 'إ': 43, 'ڕ': 44, 'ئ': 45, 'ک': 46, '١': 47, '٢': 48, '٣': 49, '٤': 50, '٥': 51, '٦': 52, '٧': 53, '٨': 54, '٩': 55, '٠': 56, '0': 57, '1': 58, '2': 59, '3': 60, '4': 61, '5': 62, '6': 63, '7': 64, '8': 65, '9': 66, '\\t': 67, '\\n': 68, '#': 69}\n",
            "{0: '\"', 1: '‘', 2: 'ی', 3: '،', 4: '.', 5: '؟', 6: '!', 38: 'ي', 8: 'ـ', 9: 'ا', 10: 'ب', 11: 'ت', 12: 'ة', 13: 'ث', 14: 'ج', 15: 'ح', 16: 'خ', 17: 'د', 18: 'ذ', 19: 'ر', 20: 'ز', 21: 'س', 22: 'ش', 23: 'ص', 24: 'ض', 25: 'ط', 26: 'ظ', 27: 'ع', 28: 'غ', 29: 'ف', 30: 'ق', 31: 'ك', 32: 'ل', 33: 'م', 34: 'ن', 35: 'ه', 36: 'و', 37: 'ى', 39: 'ء', 40: 'آ', 41: 'أ', 42: 'ؤ', 43: 'إ', 44: 'ڕ', 45: 'ئ', 46: 'ک', 47: '١', 48: '٢', 49: '٣', 50: '٤', 51: '٥', 52: '٦', 53: '٧', 54: '٨', 55: '٩', 56: '٠', 57: '0', 58: '1', 59: '2', 60: '3', 61: '4', 62: '5', 63: '6', 64: '7', 65: '8', 66: '9', 67: '\\t', 68: '\\n', 69: '#'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rKZF4tGkoJh",
        "outputId": "feea87f9-d5a4-40b6-fc3f-2cefcd75627d"
      },
      "source": [
        "import random\n",
        "#thresh - 0 to 1\n",
        "def gen_gibberish(line,thresh=0.2):\n",
        "    times = int(random.randrange(1,len(line)) * thresh)\n",
        "    '''\n",
        "    Types of replacement:\n",
        "        1.Delete random character.\n",
        "        2.Add random character.\n",
        "        3.Replace a character.\n",
        "        4.Combination?\n",
        "    '''\n",
        "   \n",
        "    while times!=0:\n",
        "        # try to gen noise length times...\n",
        "        times-=1\n",
        "        val = random.randrange(0,10)\n",
        "     \n",
        "        if val <= 5:\n",
        "            #get random index\n",
        "            val = random.randrange(0,10)\n",
        "            index = random.randrange(2,len(line))\n",
        "           \n",
        "            if val <= 3 :\n",
        "                #delete character\n",
        "                line = line[:index]+line[index+1:]\n",
        "             \n",
        "            else:\n",
        "                #add character\n",
        "                insert_index = random.randrange(0,len(char_set))\n",
        "                line = line[:index] + char_set[insert_index] + line[index:]\n",
        "             \n",
        "        else:\n",
        "            #replace index\n",
        "            index = random.randrange(0,len(char_set))\n",
        "            replace_index = random.randrange(2,len(line))\n",
        "            line = line[:replace_index] + char_set[index] + line[replace_index+1:]\n",
        "           \n",
        "           \n",
        "    return line\n",
        "\n",
        "sample = lines[100]\n",
        "gib = gen_gibberish(sample)\n",
        "print(\"Original:\",sample)\n",
        "print(\"Gibberish:\",gib)\n",
        "        "
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: فالوهابيون\n",
            "Gibberish: فالو9ابيون\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90Qgjc3Akp1t",
        "outputId": "c65ffb4c-d25e-4f38-f9ae-0c58dfa351ba"
      },
      "source": [
        "# create dataset\n",
        "input_texts = []  #the gibberished words 65%\n",
        "target_texts = [] #the original words 65%\n",
        "REPEAT_FACTOR = 1\n",
        "SKIP = int(len(lines)*0.65) #remove 65% of the data \n",
        "print(\"skip:\",SKIP)\n",
        "for line in lines[SKIP:]:\n",
        "    if len(line)>2: #words greater than 2 \n",
        "        output_text = '\\t' + line + '\\n'\n",
        "        for _ in range(REPEAT_FACTOR):\n",
        "            input_text = gen_gibberish(line)\n",
        "            input_texts.append(input_text)\n",
        "            target_texts.append(output_text)\n",
        "print(\"LEN OF SAMPLES:\",len(input_texts))\n",
        "print(\"input_texts\",input_texts[:4])\n",
        "print(\"target_texts\",target_texts[:4])"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "skip: 66740\n",
            "LEN OF SAMPLES: 35719\n",
            "input_texts ['نتنزحر', 'وقتلوه', 'سجنوه', 'أر؟لته']\n",
            "target_texts ['\\tنتناحر\\n', '\\tوقتلوه\\n', '\\tسجنوه\\n', '\\tأرسلته\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcQqMB9Xkrf0",
        "outputId": "01cc9473-2360-400a-bddc-320cddb39401"
      },
      "source": [
        "max_enc_len = max([len(x) for x in input_texts])\n",
        "\n",
        "max_dec_len = max([len(x) for x in target_texts])\n",
        "\n",
        "print(\"Max Enc Len:\",max_enc_len)\n",
        "print(\"Max Dec Len:\",max_dec_len)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Enc Len: 18\n",
            "Max Dec Len: 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvvtX35JktQj",
        "outputId": "5ba60390-5e30-409c-a264-090b4db322ba"
      },
      "source": [
        "num_samples = len(input_texts)\n",
        "encoder_input_data = np.zeros( (num_samples , max_enc_len , len(char_set)),dtype='float32' )\n",
        "decoder_input_data = np.zeros( (num_samples , max_dec_len , len(char_set)+2),dtype='float32' )\n",
        "decoder_target_data = np.zeros( (num_samples , max_dec_len , len(char_set)+2),dtype='float32' )\n",
        "print(\"CREATED ZERO VECTORS\")"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CREATED ZERO VECTORS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yhhgdC_kvGq",
        "outputId": "1028af14-baa0-446f-89ea-ecdfd57dabb4"
      },
      "source": [
        "#filling in the enc,dec datas\n",
        "for i,(input_text,target_text) in enumerate(zip(input_texts,target_texts)): #enumerate : keep a count of iterations\n",
        "    for t,char in enumerate(input_text):\n",
        "        encoder_input_data[ i , t , char2int[char] ] = 1  #i=index of word, t=index of char, cha2int[char]=index of char in our char dict \n",
        "                                                          #assign all of that to 1 in encoder\n",
        "    for t,char in enumerate(target_text):\n",
        "        decoder_input_data[ i, t , char2int[char] ] = 1\n",
        "        \n",
        "        if t > 0 :\n",
        "            decoder_target_data[ i , t-1 , char2int[char] ] = 1 #as the word starts with \\t and end with \\n\n",
        "\n",
        "print(\"COMPLETED...\")    \n"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMPLETED...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrWvF-3bkxSC"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input,LSTM,Dense"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIygmV9Cky-u"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 1000\n",
        "latent_dim = 256  #embedding dimentions\n",
        "\n",
        "num_enc_tokens = len(char_set)\n",
        "num_dec_tokens = len(char_set) + 2 # includes \\n \\t\n",
        "encoder_inputs = Input(shape=(None,num_enc_tokens))\n",
        "encoder = LSTM(latent_dim,return_state=True) #return_state: need to have its cell state initialized with previous time step while the weights are shared\n",
        "encoder_outputs , state_h, state_c = encoder(encoder_inputs)\n",
        "encoder_states = [state_h,state_c]\n"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3usEHeNlk0mS",
        "outputId": "4da72dca-8110-4cdc-a176-0ddcc394d06f"
      },
      "source": [
        "decoder_inputs = Input(shape=(None,num_dec_tokens))\n",
        "#return sequences return the hidden state output for each input time step.\n",
        "#return state returns the hidden state output and cell state for the last input time step\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "decoder_ouputs,_,_ = decoder_lstm(decoder_inputs,initial_state = encoder_states)\n",
        "\n",
        "decoder_dense = Dense(num_dec_tokens, activation='softmax')\n",
        "decoder_ouputs = decoder_dense(decoder_ouputs)\n",
        "\n",
        "model = Model([encoder_inputs,decoder_inputs],decoder_ouputs)\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, None, 67)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, None, 69)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 256), (None, 331776      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 256),  333824      input_4[0][0]                    \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 69)     17733       lstm_3[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 683,333\n",
            "Trainable params: 683,333\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdmq1TuUk2W9",
        "outputId": "47e404c6-61ae-4bce-8488-a0e2eefe110d"
      },
      "source": [
        "h=model.fit([encoder_input_data,decoder_input_data],decoder_target_data\n",
        "         ,epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.2\n",
        "         )\n",
        "model.save('s2s.h5')"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "224/224 [==============================] - 22s 14ms/step - loss: 1.1653 - val_loss: 1.0074\n",
            "Epoch 2/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.9823 - val_loss: 0.8928\n",
            "Epoch 3/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.8648 - val_loss: 0.7759\n",
            "Epoch 4/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.7568 - val_loss: 0.6877\n",
            "Epoch 5/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.6681 - val_loss: 0.6043\n",
            "Epoch 6/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.6003 - val_loss: 0.5867\n",
            "Epoch 7/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.5512 - val_loss: 0.5111\n",
            "Epoch 8/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.5108 - val_loss: 0.4786\n",
            "Epoch 9/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.4801 - val_loss: 0.4754\n",
            "Epoch 10/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.4549 - val_loss: 0.4096\n",
            "Epoch 11/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.4391 - val_loss: 0.4364\n",
            "Epoch 12/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.4242 - val_loss: 0.3945\n",
            "Epoch 13/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.4120 - val_loss: 0.4114\n",
            "Epoch 14/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.3987 - val_loss: 0.4524\n",
            "Epoch 15/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.3904 - val_loss: 0.3816\n",
            "Epoch 16/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.3771 - val_loss: 0.3827\n",
            "Epoch 17/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.3682 - val_loss: 0.3700\n",
            "Epoch 18/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.3540 - val_loss: 0.3973\n",
            "Epoch 19/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.3472 - val_loss: 0.3769\n",
            "Epoch 20/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.3372 - val_loss: 0.3816\n",
            "Epoch 21/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.3285 - val_loss: 0.3135\n",
            "Epoch 22/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.3159 - val_loss: 0.2929\n",
            "Epoch 23/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.3084 - val_loss: 0.3053\n",
            "Epoch 24/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.3022 - val_loss: 0.3070\n",
            "Epoch 25/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2955 - val_loss: 0.3036\n",
            "Epoch 26/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2887 - val_loss: 0.3156\n",
            "Epoch 27/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2835 - val_loss: 0.3115\n",
            "Epoch 28/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2765 - val_loss: 0.3151\n",
            "Epoch 29/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2736 - val_loss: 0.2789\n",
            "Epoch 30/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2686 - val_loss: 0.2882\n",
            "Epoch 31/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2620 - val_loss: 0.2612\n",
            "Epoch 32/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2578 - val_loss: 0.3307\n",
            "Epoch 33/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2540 - val_loss: 0.2589\n",
            "Epoch 34/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.2467 - val_loss: 0.2686\n",
            "Epoch 35/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2408 - val_loss: 0.2729\n",
            "Epoch 36/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2365 - val_loss: 0.2514\n",
            "Epoch 37/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2332 - val_loss: 0.2745\n",
            "Epoch 38/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2296 - val_loss: 0.2525\n",
            "Epoch 39/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2247 - val_loss: 0.2449\n",
            "Epoch 40/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2184 - val_loss: 0.2401\n",
            "Epoch 41/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2153 - val_loss: 0.2351\n",
            "Epoch 42/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2121 - val_loss: 0.2351\n",
            "Epoch 43/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2085 - val_loss: 0.2405\n",
            "Epoch 44/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2075 - val_loss: 0.3066\n",
            "Epoch 45/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2066 - val_loss: 0.2249\n",
            "Epoch 46/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.2012 - val_loss: 0.2185\n",
            "Epoch 47/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1976 - val_loss: 0.2171\n",
            "Epoch 48/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1947 - val_loss: 0.2281\n",
            "Epoch 49/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.1924 - val_loss: 0.2181\n",
            "Epoch 50/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.1902 - val_loss: 0.2560\n",
            "Epoch 51/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1899 - val_loss: 0.2209\n",
            "Epoch 52/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1858 - val_loss: 0.2276\n",
            "Epoch 53/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1824 - val_loss: 0.2299\n",
            "Epoch 54/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1812 - val_loss: 0.2077\n",
            "Epoch 55/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1775 - val_loss: 0.2061\n",
            "Epoch 56/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1726 - val_loss: 0.2092\n",
            "Epoch 57/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1750 - val_loss: 0.1997\n",
            "Epoch 58/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1724 - val_loss: 0.2133\n",
            "Epoch 59/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1689 - val_loss: 0.2091\n",
            "Epoch 60/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1673 - val_loss: 0.2019\n",
            "Epoch 61/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1645 - val_loss: 0.2082\n",
            "Epoch 62/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1629 - val_loss: 0.1954\n",
            "Epoch 63/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.1615 - val_loss: 0.2219\n",
            "Epoch 64/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.1583 - val_loss: 0.1969\n",
            "Epoch 65/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.1553 - val_loss: 0.1970\n",
            "Epoch 66/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.1543 - val_loss: 0.1886\n",
            "Epoch 67/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1524 - val_loss: 0.1911\n",
            "Epoch 68/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.1516 - val_loss: 0.1944\n",
            "Epoch 69/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1519 - val_loss: 0.1928\n",
            "Epoch 70/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.1482 - val_loss: 0.1984\n",
            "Epoch 71/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.1478 - val_loss: 0.1869\n",
            "Epoch 72/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.1483 - val_loss: 0.1823\n",
            "Epoch 73/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.1446 - val_loss: 0.1943\n",
            "Epoch 74/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1447 - val_loss: 0.1882\n",
            "Epoch 75/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1423 - val_loss: 0.1872\n",
            "Epoch 76/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1405 - val_loss: 0.1891\n",
            "Epoch 77/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.1378 - val_loss: 0.1835\n",
            "Epoch 78/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1368 - val_loss: 0.1796\n",
            "Epoch 79/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1330 - val_loss: 0.1817\n",
            "Epoch 80/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.1326 - val_loss: 0.1791\n",
            "Epoch 81/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1323 - val_loss: 0.1791\n",
            "Epoch 82/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1295 - val_loss: 0.1757\n",
            "Epoch 83/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1304 - val_loss: 0.1812\n",
            "Epoch 84/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1267 - val_loss: 0.1779\n",
            "Epoch 85/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1268 - val_loss: 0.1750\n",
            "Epoch 86/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1241 - val_loss: 0.1761\n",
            "Epoch 87/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1217 - val_loss: 0.1704\n",
            "Epoch 88/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1203 - val_loss: 0.1744\n",
            "Epoch 89/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1202 - val_loss: 0.1705\n",
            "Epoch 90/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1182 - val_loss: 0.1703\n",
            "Epoch 91/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.1156 - val_loss: 0.1665\n",
            "Epoch 92/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.1135 - val_loss: 0.1761\n",
            "Epoch 93/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1141 - val_loss: 0.1727\n",
            "Epoch 94/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1116 - val_loss: 0.1662\n",
            "Epoch 95/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1111 - val_loss: 0.1682\n",
            "Epoch 96/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1091 - val_loss: 0.1641\n",
            "Epoch 97/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.1073 - val_loss: 0.1680\n",
            "Epoch 98/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1081 - val_loss: 0.1612\n",
            "Epoch 99/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1060 - val_loss: 0.1617\n",
            "Epoch 100/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1045 - val_loss: 0.1721\n",
            "Epoch 101/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1042 - val_loss: 0.1615\n",
            "Epoch 102/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1033 - val_loss: 0.1598\n",
            "Epoch 103/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1019 - val_loss: 0.1651\n",
            "Epoch 104/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1011 - val_loss: 0.1654\n",
            "Epoch 105/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.1007 - val_loss: 0.1724\n",
            "Epoch 106/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0990 - val_loss: 0.1592\n",
            "Epoch 107/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0977 - val_loss: 0.1583\n",
            "Epoch 108/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0970 - val_loss: 0.1589\n",
            "Epoch 109/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0953 - val_loss: 0.1558\n",
            "Epoch 110/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0953 - val_loss: 0.1565\n",
            "Epoch 111/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0957 - val_loss: 0.1573\n",
            "Epoch 112/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0933 - val_loss: 0.1587\n",
            "Epoch 113/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0924 - val_loss: 0.1579\n",
            "Epoch 114/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0917 - val_loss: 0.1692\n",
            "Epoch 115/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0931 - val_loss: 0.1648\n",
            "Epoch 116/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0912 - val_loss: 0.1580\n",
            "Epoch 117/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0916 - val_loss: 0.1576\n",
            "Epoch 118/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0903 - val_loss: 0.1565\n",
            "Epoch 119/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0898 - val_loss: 0.1589\n",
            "Epoch 120/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0892 - val_loss: 0.1577\n",
            "Epoch 121/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0884 - val_loss: 0.1542\n",
            "Epoch 122/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0882 - val_loss: 0.1869\n",
            "Epoch 123/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0902 - val_loss: 0.1568\n",
            "Epoch 124/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0884 - val_loss: 0.1604\n",
            "Epoch 125/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0880 - val_loss: 0.1567\n",
            "Epoch 126/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0879 - val_loss: 0.1535\n",
            "Epoch 127/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0883 - val_loss: 0.1578\n",
            "Epoch 128/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0869 - val_loss: 0.1637\n",
            "Epoch 129/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0858 - val_loss: 0.1547\n",
            "Epoch 130/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0869 - val_loss: 0.1549\n",
            "Epoch 131/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0843 - val_loss: 0.1557\n",
            "Epoch 132/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0850 - val_loss: 0.1526\n",
            "Epoch 133/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0838 - val_loss: 0.1563\n",
            "Epoch 134/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0836 - val_loss: 0.1546\n",
            "Epoch 135/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0824 - val_loss: 0.1542\n",
            "Epoch 136/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0819 - val_loss: 0.1521\n",
            "Epoch 137/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0810 - val_loss: 0.1519\n",
            "Epoch 138/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0807 - val_loss: 0.1504\n",
            "Epoch 139/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0781 - val_loss: 0.1520\n",
            "Epoch 140/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0791 - val_loss: 0.1500\n",
            "Epoch 141/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0789 - val_loss: 0.1530\n",
            "Epoch 142/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0776 - val_loss: 0.1510\n",
            "Epoch 143/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0774 - val_loss: 0.1529\n",
            "Epoch 144/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0776 - val_loss: 0.1507\n",
            "Epoch 145/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0763 - val_loss: 0.1510\n",
            "Epoch 146/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0751 - val_loss: 0.1573\n",
            "Epoch 147/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0762 - val_loss: 0.1533\n",
            "Epoch 148/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0746 - val_loss: 0.1474\n",
            "Epoch 149/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0738 - val_loss: 0.1486\n",
            "Epoch 150/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0732 - val_loss: 0.1496\n",
            "Epoch 151/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0736 - val_loss: 0.1484\n",
            "Epoch 152/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0722 - val_loss: 0.1513\n",
            "Epoch 153/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0729 - val_loss: 0.1513\n",
            "Epoch 154/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0726 - val_loss: 0.1511\n",
            "Epoch 155/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0715 - val_loss: 0.1487\n",
            "Epoch 156/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0719 - val_loss: 0.1502\n",
            "Epoch 157/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0713 - val_loss: 0.1507\n",
            "Epoch 158/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0706 - val_loss: 0.1507\n",
            "Epoch 159/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0702 - val_loss: 0.1507\n",
            "Epoch 160/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0697 - val_loss: 0.1561\n",
            "Epoch 161/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0694 - val_loss: 0.1504\n",
            "Epoch 162/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0686 - val_loss: 0.1530\n",
            "Epoch 163/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0687 - val_loss: 0.1490\n",
            "Epoch 164/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0690 - val_loss: 0.1478\n",
            "Epoch 165/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0694 - val_loss: 0.1476\n",
            "Epoch 166/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0680 - val_loss: 0.1484\n",
            "Epoch 167/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0686 - val_loss: 0.1641\n",
            "Epoch 168/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0673 - val_loss: 0.1502\n",
            "Epoch 169/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0665 - val_loss: 0.1518\n",
            "Epoch 170/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0669 - val_loss: 0.1521\n",
            "Epoch 171/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0668 - val_loss: 0.1507\n",
            "Epoch 172/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0661 - val_loss: 0.1473\n",
            "Epoch 173/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0665 - val_loss: 0.1549\n",
            "Epoch 174/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0659 - val_loss: 0.1549\n",
            "Epoch 175/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0673 - val_loss: 0.1509\n",
            "Epoch 176/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0658 - val_loss: 0.1483\n",
            "Epoch 177/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0647 - val_loss: 0.1497\n",
            "Epoch 178/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0642 - val_loss: 0.1497\n",
            "Epoch 179/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0629 - val_loss: 0.1480\n",
            "Epoch 180/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0639 - val_loss: 0.1453\n",
            "Epoch 181/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0646 - val_loss: 0.1489\n",
            "Epoch 182/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0642 - val_loss: 0.1491\n",
            "Epoch 183/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0625 - val_loss: 0.1503\n",
            "Epoch 184/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0630 - val_loss: 0.1500\n",
            "Epoch 185/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0629 - val_loss: 0.1484\n",
            "Epoch 186/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0614 - val_loss: 0.1512\n",
            "Epoch 187/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0631 - val_loss: 0.1491\n",
            "Epoch 188/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0633 - val_loss: 0.1475\n",
            "Epoch 189/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0617 - val_loss: 0.1546\n",
            "Epoch 190/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0620 - val_loss: 0.1473\n",
            "Epoch 191/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0619 - val_loss: 0.1476\n",
            "Epoch 192/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0615 - val_loss: 0.1501\n",
            "Epoch 193/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0607 - val_loss: 0.1451\n",
            "Epoch 194/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0596 - val_loss: 0.1490\n",
            "Epoch 195/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0603 - val_loss: 0.1485\n",
            "Epoch 196/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0597 - val_loss: 0.1607\n",
            "Epoch 197/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0626 - val_loss: 0.1532\n",
            "Epoch 198/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0590 - val_loss: 0.1473\n",
            "Epoch 199/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0591 - val_loss: 0.1517\n",
            "Epoch 200/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0591 - val_loss: 0.1496\n",
            "Epoch 201/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0578 - val_loss: 0.1491\n",
            "Epoch 202/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0585 - val_loss: 0.1518\n",
            "Epoch 203/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0577 - val_loss: 0.1470\n",
            "Epoch 204/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0569 - val_loss: 0.1495\n",
            "Epoch 205/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0576 - val_loss: 0.1481\n",
            "Epoch 206/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0576 - val_loss: 0.1473\n",
            "Epoch 207/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0570 - val_loss: 0.1514\n",
            "Epoch 208/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0563 - val_loss: 0.1503\n",
            "Epoch 209/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0573 - val_loss: 0.1477\n",
            "Epoch 210/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0568 - val_loss: 0.1456\n",
            "Epoch 211/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0573 - val_loss: 0.1446\n",
            "Epoch 212/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0554 - val_loss: 0.1493\n",
            "Epoch 213/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0564 - val_loss: 0.1534\n",
            "Epoch 214/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0575 - val_loss: 0.1480\n",
            "Epoch 215/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0563 - val_loss: 0.1493\n",
            "Epoch 216/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0558 - val_loss: 0.1532\n",
            "Epoch 217/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0559 - val_loss: 0.1502\n",
            "Epoch 218/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0556 - val_loss: 0.1527\n",
            "Epoch 219/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0557 - val_loss: 0.1475\n",
            "Epoch 220/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0552 - val_loss: 0.1483\n",
            "Epoch 221/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0560 - val_loss: 0.1487\n",
            "Epoch 222/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0565 - val_loss: 0.1502\n",
            "Epoch 223/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0550 - val_loss: 0.1515\n",
            "Epoch 224/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0551 - val_loss: 0.1493\n",
            "Epoch 225/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0549 - val_loss: 0.1506\n",
            "Epoch 226/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0544 - val_loss: 0.1497\n",
            "Epoch 227/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0543 - val_loss: 0.1490\n",
            "Epoch 228/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0540 - val_loss: 0.1530\n",
            "Epoch 229/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0538 - val_loss: 0.1532\n",
            "Epoch 230/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0530 - val_loss: 0.1476\n",
            "Epoch 231/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0531 - val_loss: 0.1514\n",
            "Epoch 232/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0537 - val_loss: 0.1490\n",
            "Epoch 233/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0522 - val_loss: 0.1478\n",
            "Epoch 234/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0535 - val_loss: 0.1467\n",
            "Epoch 235/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0522 - val_loss: 0.1513\n",
            "Epoch 236/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0524 - val_loss: 0.1493\n",
            "Epoch 237/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0524 - val_loss: 0.1504\n",
            "Epoch 238/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0511 - val_loss: 0.1462\n",
            "Epoch 239/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0503 - val_loss: 0.1500\n",
            "Epoch 240/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0520 - val_loss: 0.1465\n",
            "Epoch 241/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0509 - val_loss: 0.1450\n",
            "Epoch 242/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0511 - val_loss: 0.1502\n",
            "Epoch 243/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0506 - val_loss: 0.1478\n",
            "Epoch 244/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0502 - val_loss: 0.1494\n",
            "Epoch 245/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0498 - val_loss: 0.1481\n",
            "Epoch 246/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0499 - val_loss: 0.1496\n",
            "Epoch 247/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0502 - val_loss: 0.1622\n",
            "Epoch 248/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0496 - val_loss: 0.1503\n",
            "Epoch 249/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0495 - val_loss: 0.1533\n",
            "Epoch 250/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0493 - val_loss: 0.1479\n",
            "Epoch 251/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0497 - val_loss: 0.1536\n",
            "Epoch 252/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0499 - val_loss: 0.1514\n",
            "Epoch 253/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0499 - val_loss: 0.1486\n",
            "Epoch 254/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0489 - val_loss: 0.1544\n",
            "Epoch 255/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0497 - val_loss: 0.1521\n",
            "Epoch 256/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0491 - val_loss: 0.1502\n",
            "Epoch 257/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0486 - val_loss: 0.1538\n",
            "Epoch 258/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0491 - val_loss: 0.1472\n",
            "Epoch 259/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0484 - val_loss: 0.1490\n",
            "Epoch 260/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0482 - val_loss: 0.1523\n",
            "Epoch 261/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0478 - val_loss: 0.1501\n",
            "Epoch 262/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0477 - val_loss: 0.1502\n",
            "Epoch 263/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0479 - val_loss: 0.1526\n",
            "Epoch 264/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0471 - val_loss: 0.1526\n",
            "Epoch 265/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0486 - val_loss: 0.1512\n",
            "Epoch 266/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0488 - val_loss: 0.1496\n",
            "Epoch 267/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0477 - val_loss: 0.1510\n",
            "Epoch 268/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0466 - val_loss: 0.1478\n",
            "Epoch 269/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0476 - val_loss: 0.1480\n",
            "Epoch 270/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0466 - val_loss: 0.1494\n",
            "Epoch 271/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0476 - val_loss: 0.1489\n",
            "Epoch 272/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0472 - val_loss: 0.1469\n",
            "Epoch 273/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0468 - val_loss: 0.1488\n",
            "Epoch 274/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0470 - val_loss: 0.1494\n",
            "Epoch 275/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0458 - val_loss: 0.1489\n",
            "Epoch 276/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0465 - val_loss: 0.1481\n",
            "Epoch 277/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0463 - val_loss: 0.1457\n",
            "Epoch 278/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0455 - val_loss: 0.1463\n",
            "Epoch 279/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0457 - val_loss: 0.1493\n",
            "Epoch 280/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0458 - val_loss: 0.1496\n",
            "Epoch 281/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0461 - val_loss: 0.1509\n",
            "Epoch 282/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0461 - val_loss: 0.1487\n",
            "Epoch 283/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0455 - val_loss: 0.1514\n",
            "Epoch 284/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0448 - val_loss: 0.1495\n",
            "Epoch 285/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0457 - val_loss: 0.1502\n",
            "Epoch 286/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0443 - val_loss: 0.1462\n",
            "Epoch 287/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0447 - val_loss: 0.1481\n",
            "Epoch 288/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0446 - val_loss: 0.1501\n",
            "Epoch 289/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0446 - val_loss: 0.1500\n",
            "Epoch 290/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0448 - val_loss: 0.1503\n",
            "Epoch 291/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0437 - val_loss: 0.1488\n",
            "Epoch 292/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0449 - val_loss: 0.1476\n",
            "Epoch 293/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0434 - val_loss: 0.1478\n",
            "Epoch 294/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0450 - val_loss: 0.1489\n",
            "Epoch 295/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0433 - val_loss: 0.1482\n",
            "Epoch 296/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0438 - val_loss: 0.1508\n",
            "Epoch 297/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0437 - val_loss: 0.1482\n",
            "Epoch 298/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0437 - val_loss: 0.1496\n",
            "Epoch 299/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0437 - val_loss: 0.1477\n",
            "Epoch 300/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0431 - val_loss: 0.1502\n",
            "Epoch 301/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0431 - val_loss: 0.1492\n",
            "Epoch 302/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0438 - val_loss: 0.1498\n",
            "Epoch 303/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0435 - val_loss: 0.1472\n",
            "Epoch 304/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0429 - val_loss: 0.1512\n",
            "Epoch 305/1000\n",
            "224/224 [==============================] - 2s 10ms/step - loss: 0.0432 - val_loss: 0.1469\n",
            "Epoch 306/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0435 - val_loss: 0.1500\n",
            "Epoch 307/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0428 - val_loss: 0.1484\n",
            "Epoch 308/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0425 - val_loss: 0.1522\n",
            "Epoch 309/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0425 - val_loss: 0.1473\n",
            "Epoch 310/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0430 - val_loss: 0.1491\n",
            "Epoch 311/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0424 - val_loss: 0.1486\n",
            "Epoch 312/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0423 - val_loss: 0.1548\n",
            "Epoch 313/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0419 - val_loss: 0.1484\n",
            "Epoch 314/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0418 - val_loss: 0.1525\n",
            "Epoch 315/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0421 - val_loss: 0.1516\n",
            "Epoch 316/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0427 - val_loss: 0.1491\n",
            "Epoch 317/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0415 - val_loss: 0.1476\n",
            "Epoch 318/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0417 - val_loss: 0.1473\n",
            "Epoch 319/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0417 - val_loss: 0.1470\n",
            "Epoch 320/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0407 - val_loss: 0.1564\n",
            "Epoch 321/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0416 - val_loss: 0.1505\n",
            "Epoch 322/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0420 - val_loss: 0.1486\n",
            "Epoch 323/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0413 - val_loss: 0.1500\n",
            "Epoch 324/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0400 - val_loss: 0.1572\n",
            "Epoch 325/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0413 - val_loss: 0.1489\n",
            "Epoch 326/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0408 - val_loss: 0.1486\n",
            "Epoch 327/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0403 - val_loss: 0.1484\n",
            "Epoch 328/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0413 - val_loss: 0.1499\n",
            "Epoch 329/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0406 - val_loss: 0.1466\n",
            "Epoch 330/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0408 - val_loss: 0.1560\n",
            "Epoch 331/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0416 - val_loss: 0.1496\n",
            "Epoch 332/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0408 - val_loss: 0.1517\n",
            "Epoch 333/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0417 - val_loss: 0.1480\n",
            "Epoch 334/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0407 - val_loss: 0.1524\n",
            "Epoch 335/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0410 - val_loss: 0.1510\n",
            "Epoch 336/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0406 - val_loss: 0.1524\n",
            "Epoch 337/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0405 - val_loss: 0.1502\n",
            "Epoch 338/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0412 - val_loss: 0.1502\n",
            "Epoch 339/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0399 - val_loss: 0.1504\n",
            "Epoch 340/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0414 - val_loss: 0.1470\n",
            "Epoch 341/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0411 - val_loss: 0.1471\n",
            "Epoch 342/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0412 - val_loss: 0.1529\n",
            "Epoch 343/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0418 - val_loss: 0.1500\n",
            "Epoch 344/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0417 - val_loss: 0.1537\n",
            "Epoch 345/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0415 - val_loss: 0.1531\n",
            "Epoch 346/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0403 - val_loss: 0.1501\n",
            "Epoch 347/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0402 - val_loss: 0.1508\n",
            "Epoch 348/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0400 - val_loss: 0.1529\n",
            "Epoch 349/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0403 - val_loss: 0.1527\n",
            "Epoch 350/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0408 - val_loss: 0.1490\n",
            "Epoch 351/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0396 - val_loss: 0.1535\n",
            "Epoch 352/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0398 - val_loss: 0.1527\n",
            "Epoch 353/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0398 - val_loss: 0.1480\n",
            "Epoch 354/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0398 - val_loss: 0.1505\n",
            "Epoch 355/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0396 - val_loss: 0.1490\n",
            "Epoch 356/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0393 - val_loss: 0.1505\n",
            "Epoch 357/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0395 - val_loss: 0.1482\n",
            "Epoch 358/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0390 - val_loss: 0.1508\n",
            "Epoch 359/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0391 - val_loss: 0.1500\n",
            "Epoch 360/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0383 - val_loss: 0.1515\n",
            "Epoch 361/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0377 - val_loss: 0.1488\n",
            "Epoch 362/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0382 - val_loss: 0.1545\n",
            "Epoch 363/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0394 - val_loss: 0.1493\n",
            "Epoch 364/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0383 - val_loss: 0.1479\n",
            "Epoch 365/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0382 - val_loss: 0.1513\n",
            "Epoch 366/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0379 - val_loss: 0.1514\n",
            "Epoch 367/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0394 - val_loss: 0.1491\n",
            "Epoch 368/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0374 - val_loss: 0.1509\n",
            "Epoch 369/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0382 - val_loss: 0.1504\n",
            "Epoch 370/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0383 - val_loss: 0.1486\n",
            "Epoch 371/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0377 - val_loss: 0.1505\n",
            "Epoch 372/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0375 - val_loss: 0.1510\n",
            "Epoch 373/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0373 - val_loss: 0.1488\n",
            "Epoch 374/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0373 - val_loss: 0.1499\n",
            "Epoch 375/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0370 - val_loss: 0.1488\n",
            "Epoch 376/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0367 - val_loss: 0.1488\n",
            "Epoch 377/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0367 - val_loss: 0.1492\n",
            "Epoch 378/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0365 - val_loss: 0.1503\n",
            "Epoch 379/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0374 - val_loss: 0.1503\n",
            "Epoch 380/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0363 - val_loss: 0.1506\n",
            "Epoch 381/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0365 - val_loss: 0.1493\n",
            "Epoch 382/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0363 - val_loss: 0.1534\n",
            "Epoch 383/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0367 - val_loss: 0.1479\n",
            "Epoch 384/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0364 - val_loss: 0.1491\n",
            "Epoch 385/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0363 - val_loss: 0.1505\n",
            "Epoch 386/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0361 - val_loss: 0.1525\n",
            "Epoch 387/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0359 - val_loss: 0.1506\n",
            "Epoch 388/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0360 - val_loss: 0.1488\n",
            "Epoch 389/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0357 - val_loss: 0.1543\n",
            "Epoch 390/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0363 - val_loss: 0.1500\n",
            "Epoch 391/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0354 - val_loss: 0.1495\n",
            "Epoch 392/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0359 - val_loss: 0.1513\n",
            "Epoch 393/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0352 - val_loss: 0.1481\n",
            "Epoch 394/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0343 - val_loss: 0.1513\n",
            "Epoch 395/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0353 - val_loss: 0.1542\n",
            "Epoch 396/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0355 - val_loss: 0.1515\n",
            "Epoch 397/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0353 - val_loss: 0.1485\n",
            "Epoch 398/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0352 - val_loss: 0.1496\n",
            "Epoch 399/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0360 - val_loss: 0.1462\n",
            "Epoch 400/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0356 - val_loss: 0.1484\n",
            "Epoch 401/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0353 - val_loss: 0.1476\n",
            "Epoch 402/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0351 - val_loss: 0.1484\n",
            "Epoch 403/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0346 - val_loss: 0.1492\n",
            "Epoch 404/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0347 - val_loss: 0.1493\n",
            "Epoch 405/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0343 - val_loss: 0.1501\n",
            "Epoch 406/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0345 - val_loss: 0.1505\n",
            "Epoch 407/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0347 - val_loss: 0.1492\n",
            "Epoch 408/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0340 - val_loss: 0.1506\n",
            "Epoch 409/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0362 - val_loss: 0.1493\n",
            "Epoch 410/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0339 - val_loss: 0.1491\n",
            "Epoch 411/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0342 - val_loss: 0.1507\n",
            "Epoch 412/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0348 - val_loss: 0.1509\n",
            "Epoch 413/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0344 - val_loss: 0.1533\n",
            "Epoch 414/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0345 - val_loss: 0.1493\n",
            "Epoch 415/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0341 - val_loss: 0.1503\n",
            "Epoch 416/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0332 - val_loss: 0.1536\n",
            "Epoch 417/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0336 - val_loss: 0.1530\n",
            "Epoch 418/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0334 - val_loss: 0.1490\n",
            "Epoch 419/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0333 - val_loss: 0.1499\n",
            "Epoch 420/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0331 - val_loss: 0.1477\n",
            "Epoch 421/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0328 - val_loss: 0.1549\n",
            "Epoch 422/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0342 - val_loss: 0.1507\n",
            "Epoch 423/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0334 - val_loss: 0.1492\n",
            "Epoch 424/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0331 - val_loss: 0.1497\n",
            "Epoch 425/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0339 - val_loss: 0.1504\n",
            "Epoch 426/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0334 - val_loss: 0.1570\n",
            "Epoch 427/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0333 - val_loss: 0.1480\n",
            "Epoch 428/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0333 - val_loss: 0.1553\n",
            "Epoch 429/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0332 - val_loss: 0.1488\n",
            "Epoch 430/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0330 - val_loss: 0.1495\n",
            "Epoch 431/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0322 - val_loss: 0.1487\n",
            "Epoch 432/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0332 - val_loss: 0.1493\n",
            "Epoch 433/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0333 - val_loss: 0.1489\n",
            "Epoch 434/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0323 - val_loss: 0.1479\n",
            "Epoch 435/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0325 - val_loss: 0.1470\n",
            "Epoch 436/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0320 - val_loss: 0.1477\n",
            "Epoch 437/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0330 - val_loss: 0.1498\n",
            "Epoch 438/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0326 - val_loss: 0.1496\n",
            "Epoch 439/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0322 - val_loss: 0.1555\n",
            "Epoch 440/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0326 - val_loss: 0.1502\n",
            "Epoch 441/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0323 - val_loss: 0.1487\n",
            "Epoch 442/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0324 - val_loss: 0.1510\n",
            "Epoch 443/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0319 - val_loss: 0.1532\n",
            "Epoch 444/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0321 - val_loss: 0.1523\n",
            "Epoch 445/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0323 - val_loss: 0.1534\n",
            "Epoch 446/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0326 - val_loss: 0.1496\n",
            "Epoch 447/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0325 - val_loss: 0.1540\n",
            "Epoch 448/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0319 - val_loss: 0.1510\n",
            "Epoch 449/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0322 - val_loss: 0.1479\n",
            "Epoch 450/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0315 - val_loss: 0.1468\n",
            "Epoch 451/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0316 - val_loss: 0.1487\n",
            "Epoch 452/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0315 - val_loss: 0.1483\n",
            "Epoch 453/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0318 - val_loss: 0.1477\n",
            "Epoch 454/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0311 - val_loss: 0.1483\n",
            "Epoch 455/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0310 - val_loss: 0.1508\n",
            "Epoch 456/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0308 - val_loss: 0.1474\n",
            "Epoch 457/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0312 - val_loss: 0.1481\n",
            "Epoch 458/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0307 - val_loss: 0.1478\n",
            "Epoch 459/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0304 - val_loss: 0.1467\n",
            "Epoch 460/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0306 - val_loss: 0.1470\n",
            "Epoch 461/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0311 - val_loss: 0.1504\n",
            "Epoch 462/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0301 - val_loss: 0.1477\n",
            "Epoch 463/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0306 - val_loss: 0.1541\n",
            "Epoch 464/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0306 - val_loss: 0.1525\n",
            "Epoch 465/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0307 - val_loss: 0.1497\n",
            "Epoch 466/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0309 - val_loss: 0.1484\n",
            "Epoch 467/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0302 - val_loss: 0.1485\n",
            "Epoch 468/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0310 - val_loss: 0.1578\n",
            "Epoch 469/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0305 - val_loss: 0.1487\n",
            "Epoch 470/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0301 - val_loss: 0.1489\n",
            "Epoch 471/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0301 - val_loss: 0.1500\n",
            "Epoch 472/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0304 - val_loss: 0.1501\n",
            "Epoch 473/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0310 - val_loss: 0.1480\n",
            "Epoch 474/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0305 - val_loss: 0.1503\n",
            "Epoch 475/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0311 - val_loss: 0.1539\n",
            "Epoch 476/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0299 - val_loss: 0.1514\n",
            "Epoch 477/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0301 - val_loss: 0.1490\n",
            "Epoch 478/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0303 - val_loss: 0.1473\n",
            "Epoch 479/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0294 - val_loss: 0.1518\n",
            "Epoch 480/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0307 - val_loss: 0.1525\n",
            "Epoch 481/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0308 - val_loss: 0.1524\n",
            "Epoch 482/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0303 - val_loss: 0.1510\n",
            "Epoch 483/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0309 - val_loss: 0.1509\n",
            "Epoch 484/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0301 - val_loss: 0.1506\n",
            "Epoch 485/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0302 - val_loss: 0.1505\n",
            "Epoch 486/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0311 - val_loss: 0.1529\n",
            "Epoch 487/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0303 - val_loss: 0.1516\n",
            "Epoch 488/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0318 - val_loss: 0.1554\n",
            "Epoch 489/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0319 - val_loss: 0.1500\n",
            "Epoch 490/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0322 - val_loss: 0.1494\n",
            "Epoch 491/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0301 - val_loss: 0.1531\n",
            "Epoch 492/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0310 - val_loss: 0.1495\n",
            "Epoch 493/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0308 - val_loss: 0.1503\n",
            "Epoch 494/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0308 - val_loss: 0.1504\n",
            "Epoch 495/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0307 - val_loss: 0.1529\n",
            "Epoch 496/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0308 - val_loss: 0.1499\n",
            "Epoch 497/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0303 - val_loss: 0.1522\n",
            "Epoch 498/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0302 - val_loss: 0.1518\n",
            "Epoch 499/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0306 - val_loss: 0.1502\n",
            "Epoch 500/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0304 - val_loss: 0.1502\n",
            "Epoch 501/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0299 - val_loss: 0.1501\n",
            "Epoch 502/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0304 - val_loss: 0.1622\n",
            "Epoch 503/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0311 - val_loss: 0.1511\n",
            "Epoch 504/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0302 - val_loss: 0.1527\n",
            "Epoch 505/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0296 - val_loss: 0.1492\n",
            "Epoch 506/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0290 - val_loss: 0.1527\n",
            "Epoch 507/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0296 - val_loss: 0.1537\n",
            "Epoch 508/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0295 - val_loss: 0.1509\n",
            "Epoch 509/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0291 - val_loss: 0.1539\n",
            "Epoch 510/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0298 - val_loss: 0.1511\n",
            "Epoch 511/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0298 - val_loss: 0.1522\n",
            "Epoch 512/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0295 - val_loss: 0.1508\n",
            "Epoch 513/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0294 - val_loss: 0.1542\n",
            "Epoch 514/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0293 - val_loss: 0.1519\n",
            "Epoch 515/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0298 - val_loss: 0.1522\n",
            "Epoch 516/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0289 - val_loss: 0.1508\n",
            "Epoch 517/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0298 - val_loss: 0.1520\n",
            "Epoch 518/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0294 - val_loss: 0.1519\n",
            "Epoch 519/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0294 - val_loss: 0.1514\n",
            "Epoch 520/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0291 - val_loss: 0.1517\n",
            "Epoch 521/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0295 - val_loss: 0.1501\n",
            "Epoch 522/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0290 - val_loss: 0.1502\n",
            "Epoch 523/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0306 - val_loss: 0.1536\n",
            "Epoch 524/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0292 - val_loss: 0.1583\n",
            "Epoch 525/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0310 - val_loss: 0.1507\n",
            "Epoch 526/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0292 - val_loss: 0.1522\n",
            "Epoch 527/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0289 - val_loss: 0.1530\n",
            "Epoch 528/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0290 - val_loss: 0.1582\n",
            "Epoch 529/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0296 - val_loss: 0.1539\n",
            "Epoch 530/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0293 - val_loss: 0.1527\n",
            "Epoch 531/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0287 - val_loss: 0.1495\n",
            "Epoch 532/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0288 - val_loss: 0.1536\n",
            "Epoch 533/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0291 - val_loss: 0.1531\n",
            "Epoch 534/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0286 - val_loss: 0.1515\n",
            "Epoch 535/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0287 - val_loss: 0.1519\n",
            "Epoch 536/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0284 - val_loss: 0.1528\n",
            "Epoch 537/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0282 - val_loss: 0.1508\n",
            "Epoch 538/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0279 - val_loss: 0.1525\n",
            "Epoch 539/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0274 - val_loss: 0.1531\n",
            "Epoch 540/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0284 - val_loss: 0.1566\n",
            "Epoch 541/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0299 - val_loss: 0.1522\n",
            "Epoch 542/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0283 - val_loss: 0.1533\n",
            "Epoch 543/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0280 - val_loss: 0.1526\n",
            "Epoch 544/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0293 - val_loss: 0.1550\n",
            "Epoch 545/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0285 - val_loss: 0.1529\n",
            "Epoch 546/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0281 - val_loss: 0.1519\n",
            "Epoch 547/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0290 - val_loss: 0.1529\n",
            "Epoch 548/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0285 - val_loss: 0.1514\n",
            "Epoch 549/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0281 - val_loss: 0.1528\n",
            "Epoch 550/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0286 - val_loss: 0.1523\n",
            "Epoch 551/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0285 - val_loss: 0.1584\n",
            "Epoch 552/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0288 - val_loss: 0.1513\n",
            "Epoch 553/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0278 - val_loss: 0.1533\n",
            "Epoch 554/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0280 - val_loss: 0.1549\n",
            "Epoch 555/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0279 - val_loss: 0.1583\n",
            "Epoch 556/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0292 - val_loss: 0.1544\n",
            "Epoch 557/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0286 - val_loss: 0.1533\n",
            "Epoch 558/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0287 - val_loss: 0.1562\n",
            "Epoch 559/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0293 - val_loss: 0.1526\n",
            "Epoch 560/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0279 - val_loss: 0.1549\n",
            "Epoch 561/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0307 - val_loss: 0.1515\n",
            "Epoch 562/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0293 - val_loss: 0.1545\n",
            "Epoch 563/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0294 - val_loss: 0.1641\n",
            "Epoch 564/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0291 - val_loss: 0.1522\n",
            "Epoch 565/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0303 - val_loss: 0.1521\n",
            "Epoch 566/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0277 - val_loss: 0.1529\n",
            "Epoch 567/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0280 - val_loss: 0.1520\n",
            "Epoch 568/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0274 - val_loss: 0.1542\n",
            "Epoch 569/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0284 - val_loss: 0.1609\n",
            "Epoch 570/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0323 - val_loss: 0.1504\n",
            "Epoch 571/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0285 - val_loss: 0.1521\n",
            "Epoch 572/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0279 - val_loss: 0.1551\n",
            "Epoch 573/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0285 - val_loss: 0.1514\n",
            "Epoch 574/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0296 - val_loss: 0.1518\n",
            "Epoch 575/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0280 - val_loss: 0.1551\n",
            "Epoch 576/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0289 - val_loss: 0.1534\n",
            "Epoch 577/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0284 - val_loss: 0.1525\n",
            "Epoch 578/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0283 - val_loss: 0.1538\n",
            "Epoch 579/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0276 - val_loss: 0.1571\n",
            "Epoch 580/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0279 - val_loss: 0.1551\n",
            "Epoch 581/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0283 - val_loss: 0.1522\n",
            "Epoch 582/1000\n",
            "224/224 [==============================] - 2s 11ms/step - loss: 0.0282 - val_loss: 0.1529\n",
            "Epoch 583/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0275 - val_loss: 0.1543\n",
            "Epoch 584/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0279 - val_loss: 0.1578\n",
            "Epoch 585/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0275 - val_loss: 0.1535\n",
            "Epoch 586/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0276 - val_loss: 0.1552\n",
            "Epoch 587/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0280 - val_loss: 0.1538\n",
            "Epoch 588/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0282 - val_loss: 0.1544\n",
            "Epoch 589/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0278 - val_loss: 0.1536\n",
            "Epoch 590/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0276 - val_loss: 0.1538\n",
            "Epoch 591/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0276 - val_loss: 0.1569\n",
            "Epoch 592/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0278 - val_loss: 0.1523\n",
            "Epoch 593/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0280 - val_loss: 0.1552\n",
            "Epoch 594/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0280 - val_loss: 0.1519\n",
            "Epoch 595/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0275 - val_loss: 0.1640\n",
            "Epoch 596/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0296 - val_loss: 0.1552\n",
            "Epoch 597/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0282 - val_loss: 0.1557\n",
            "Epoch 598/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0273 - val_loss: 0.1540\n",
            "Epoch 599/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0271 - val_loss: 0.1561\n",
            "Epoch 600/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0276 - val_loss: 0.1565\n",
            "Epoch 601/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0275 - val_loss: 0.1519\n",
            "Epoch 602/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0269 - val_loss: 0.1541\n",
            "Epoch 603/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0277 - val_loss: 0.1537\n",
            "Epoch 604/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0268 - val_loss: 0.1555\n",
            "Epoch 605/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0270 - val_loss: 0.1538\n",
            "Epoch 606/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0271 - val_loss: 0.1545\n",
            "Epoch 607/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0268 - val_loss: 0.1529\n",
            "Epoch 608/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0270 - val_loss: 0.1571\n",
            "Epoch 609/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0270 - val_loss: 0.1520\n",
            "Epoch 610/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0277 - val_loss: 0.1538\n",
            "Epoch 611/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0285 - val_loss: 0.1548\n",
            "Epoch 612/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0275 - val_loss: 0.1526\n",
            "Epoch 613/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0272 - val_loss: 0.1539\n",
            "Epoch 614/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0272 - val_loss: 0.1528\n",
            "Epoch 615/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0275 - val_loss: 0.1557\n",
            "Epoch 616/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0267 - val_loss: 0.1539\n",
            "Epoch 617/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0267 - val_loss: 0.1584\n",
            "Epoch 618/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0273 - val_loss: 0.1563\n",
            "Epoch 619/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0284 - val_loss: 0.1541\n",
            "Epoch 620/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0277 - val_loss: 0.1526\n",
            "Epoch 621/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0272 - val_loss: 0.1593\n",
            "Epoch 622/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0271 - val_loss: 0.1544\n",
            "Epoch 623/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0267 - val_loss: 0.1551\n",
            "Epoch 624/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0273 - val_loss: 0.1583\n",
            "Epoch 625/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0279 - val_loss: 0.1546\n",
            "Epoch 626/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0268 - val_loss: 0.1551\n",
            "Epoch 627/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0265 - val_loss: 0.1566\n",
            "Epoch 628/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0268 - val_loss: 0.1532\n",
            "Epoch 629/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0268 - val_loss: 0.1545\n",
            "Epoch 630/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0268 - val_loss: 0.1544\n",
            "Epoch 631/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0272 - val_loss: 0.1572\n",
            "Epoch 632/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0274 - val_loss: 0.1546\n",
            "Epoch 633/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0267 - val_loss: 0.1568\n",
            "Epoch 634/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0264 - val_loss: 0.1561\n",
            "Epoch 635/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0268 - val_loss: 0.1553\n",
            "Epoch 636/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0266 - val_loss: 0.1580\n",
            "Epoch 637/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0267 - val_loss: 0.1573\n",
            "Epoch 638/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0264 - val_loss: 0.1560\n",
            "Epoch 639/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0266 - val_loss: 0.1562\n",
            "Epoch 640/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0273 - val_loss: 0.1541\n",
            "Epoch 641/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0275 - val_loss: 0.1557\n",
            "Epoch 642/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0266 - val_loss: 0.1556\n",
            "Epoch 643/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0267 - val_loss: 0.1561\n",
            "Epoch 644/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0259 - val_loss: 0.1548\n",
            "Epoch 645/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0261 - val_loss: 0.1620\n",
            "Epoch 646/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0261 - val_loss: 0.1558\n",
            "Epoch 647/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0256 - val_loss: 0.1561\n",
            "Epoch 648/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0263 - val_loss: 0.1539\n",
            "Epoch 649/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0267 - val_loss: 0.1562\n",
            "Epoch 650/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0263 - val_loss: 0.1612\n",
            "Epoch 651/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0272 - val_loss: 0.1578\n",
            "Epoch 652/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0266 - val_loss: 0.1544\n",
            "Epoch 653/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0257 - val_loss: 0.1562\n",
            "Epoch 654/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0261 - val_loss: 0.1563\n",
            "Epoch 655/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0263 - val_loss: 0.1564\n",
            "Epoch 656/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0268 - val_loss: 0.1566\n",
            "Epoch 657/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0256 - val_loss: 0.1547\n",
            "Epoch 658/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0261 - val_loss: 0.1576\n",
            "Epoch 659/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0263 - val_loss: 0.1549\n",
            "Epoch 660/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0262 - val_loss: 0.1567\n",
            "Epoch 661/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0257 - val_loss: 0.1565\n",
            "Epoch 662/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0259 - val_loss: 0.1576\n",
            "Epoch 663/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0263 - val_loss: 0.1587\n",
            "Epoch 664/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0260 - val_loss: 0.1559\n",
            "Epoch 665/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0261 - val_loss: 0.1561\n",
            "Epoch 666/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0267 - val_loss: 0.1581\n",
            "Epoch 667/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0267 - val_loss: 0.1574\n",
            "Epoch 668/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0273 - val_loss: 0.1566\n",
            "Epoch 669/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0260 - val_loss: 0.1559\n",
            "Epoch 670/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0262 - val_loss: 0.1575\n",
            "Epoch 671/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0257 - val_loss: 0.1558\n",
            "Epoch 672/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0252 - val_loss: 0.1528\n",
            "Epoch 673/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0249 - val_loss: 0.1552\n",
            "Epoch 674/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0253 - val_loss: 0.1582\n",
            "Epoch 675/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0258 - val_loss: 0.1538\n",
            "Epoch 676/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0247 - val_loss: 0.1550\n",
            "Epoch 677/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0254 - val_loss: 0.1572\n",
            "Epoch 678/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0253 - val_loss: 0.1554\n",
            "Epoch 679/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0251 - val_loss: 0.1581\n",
            "Epoch 680/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0253 - val_loss: 0.1550\n",
            "Epoch 681/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0264 - val_loss: 0.1554\n",
            "Epoch 682/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0260 - val_loss: 0.1563\n",
            "Epoch 683/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0260 - val_loss: 0.1582\n",
            "Epoch 684/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0255 - val_loss: 0.1571\n",
            "Epoch 685/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0259 - val_loss: 0.1584\n",
            "Epoch 686/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0259 - val_loss: 0.1570\n",
            "Epoch 687/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0262 - val_loss: 0.1557\n",
            "Epoch 688/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0257 - val_loss: 0.1575\n",
            "Epoch 689/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0251 - val_loss: 0.1566\n",
            "Epoch 690/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0257 - val_loss: 0.1574\n",
            "Epoch 691/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0254 - val_loss: 0.1575\n",
            "Epoch 692/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0260 - val_loss: 0.1554\n",
            "Epoch 693/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0257 - val_loss: 0.1559\n",
            "Epoch 694/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0256 - val_loss: 0.1573\n",
            "Epoch 695/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0258 - val_loss: 0.1609\n",
            "Epoch 696/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0259 - val_loss: 0.1567\n",
            "Epoch 697/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0254 - val_loss: 0.1536\n",
            "Epoch 698/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0258 - val_loss: 0.1566\n",
            "Epoch 699/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0262 - val_loss: 0.1518\n",
            "Epoch 700/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0251 - val_loss: 0.1554\n",
            "Epoch 701/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0250 - val_loss: 0.1548\n",
            "Epoch 702/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0251 - val_loss: 0.1548\n",
            "Epoch 703/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0253 - val_loss: 0.1567\n",
            "Epoch 704/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0251 - val_loss: 0.1538\n",
            "Epoch 705/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0236 - val_loss: 0.1555\n",
            "Epoch 706/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0249 - val_loss: 0.1562\n",
            "Epoch 707/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0262 - val_loss: 0.1581\n",
            "Epoch 708/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0252 - val_loss: 0.1561\n",
            "Epoch 709/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0246 - val_loss: 0.1553\n",
            "Epoch 710/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0253 - val_loss: 0.1550\n",
            "Epoch 711/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0257 - val_loss: 0.1584\n",
            "Epoch 712/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0273 - val_loss: 0.1571\n",
            "Epoch 713/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0248 - val_loss: 0.1585\n",
            "Epoch 714/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0250 - val_loss: 0.1547\n",
            "Epoch 715/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0251 - val_loss: 0.1568\n",
            "Epoch 716/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0256 - val_loss: 0.1557\n",
            "Epoch 717/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0254 - val_loss: 0.1545\n",
            "Epoch 718/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0253 - val_loss: 0.1596\n",
            "Epoch 719/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0259 - val_loss: 0.1573\n",
            "Epoch 720/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0253 - val_loss: 0.1579\n",
            "Epoch 721/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0251 - val_loss: 0.1581\n",
            "Epoch 722/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0257 - val_loss: 0.1713\n",
            "Epoch 723/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0282 - val_loss: 0.1593\n",
            "Epoch 724/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0255 - val_loss: 0.1609\n",
            "Epoch 725/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0261 - val_loss: 0.1552\n",
            "Epoch 726/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0258 - val_loss: 0.1568\n",
            "Epoch 727/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0248 - val_loss: 0.1577\n",
            "Epoch 728/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0257 - val_loss: 0.1579\n",
            "Epoch 729/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0254 - val_loss: 0.1594\n",
            "Epoch 730/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0252 - val_loss: 0.1563\n",
            "Epoch 731/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0248 - val_loss: 0.1571\n",
            "Epoch 732/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0253 - val_loss: 0.1607\n",
            "Epoch 733/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0254 - val_loss: 0.1548\n",
            "Epoch 734/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0248 - val_loss: 0.1569\n",
            "Epoch 735/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0247 - val_loss: 0.1561\n",
            "Epoch 736/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0247 - val_loss: 0.1570\n",
            "Epoch 737/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0246 - val_loss: 0.1629\n",
            "Epoch 738/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0254 - val_loss: 0.1601\n",
            "Epoch 739/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0243 - val_loss: 0.1580\n",
            "Epoch 740/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0246 - val_loss: 0.1602\n",
            "Epoch 741/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0241 - val_loss: 0.1576\n",
            "Epoch 742/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0244 - val_loss: 0.1576\n",
            "Epoch 743/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0236 - val_loss: 0.1591\n",
            "Epoch 744/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0244 - val_loss: 0.1596\n",
            "Epoch 745/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0249 - val_loss: 0.1575\n",
            "Epoch 746/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0247 - val_loss: 0.1592\n",
            "Epoch 747/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0254 - val_loss: 0.1555\n",
            "Epoch 748/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0245 - val_loss: 0.1586\n",
            "Epoch 749/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0252 - val_loss: 0.1563\n",
            "Epoch 750/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0248 - val_loss: 0.1585\n",
            "Epoch 751/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0248 - val_loss: 0.1583\n",
            "Epoch 752/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0253 - val_loss: 0.1581\n",
            "Epoch 753/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0248 - val_loss: 0.1650\n",
            "Epoch 754/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0251 - val_loss: 0.1582\n",
            "Epoch 755/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0245 - val_loss: 0.1579\n",
            "Epoch 756/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0250 - val_loss: 0.1573\n",
            "Epoch 757/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0250 - val_loss: 0.1592\n",
            "Epoch 758/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0246 - val_loss: 0.1593\n",
            "Epoch 759/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0246 - val_loss: 0.1590\n",
            "Epoch 760/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0245 - val_loss: 0.1587\n",
            "Epoch 761/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0254 - val_loss: 0.1580\n",
            "Epoch 762/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0246 - val_loss: 0.1579\n",
            "Epoch 763/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0246 - val_loss: 0.1571\n",
            "Epoch 764/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0243 - val_loss: 0.1567\n",
            "Epoch 765/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0240 - val_loss: 0.1625\n",
            "Epoch 766/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0250 - val_loss: 0.1562\n",
            "Epoch 767/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0249 - val_loss: 0.1580\n",
            "Epoch 768/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0242 - val_loss: 0.1632\n",
            "Epoch 769/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0248 - val_loss: 0.1610\n",
            "Epoch 770/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0237 - val_loss: 0.1585\n",
            "Epoch 771/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0254 - val_loss: 0.1605\n",
            "Epoch 772/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0246 - val_loss: 0.1573\n",
            "Epoch 773/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0242 - val_loss: 0.1601\n",
            "Epoch 774/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0247 - val_loss: 0.1562\n",
            "Epoch 775/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0243 - val_loss: 0.1566\n",
            "Epoch 776/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0249 - val_loss: 0.1549\n",
            "Epoch 777/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0242 - val_loss: 0.1584\n",
            "Epoch 778/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0244 - val_loss: 0.1572\n",
            "Epoch 779/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0241 - val_loss: 0.1589\n",
            "Epoch 780/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0249 - val_loss: 0.1585\n",
            "Epoch 781/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0239 - val_loss: 0.1552\n",
            "Epoch 782/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0234 - val_loss: 0.1580\n",
            "Epoch 783/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0236 - val_loss: 0.1582\n",
            "Epoch 784/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0236 - val_loss: 0.1574\n",
            "Epoch 785/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0230 - val_loss: 0.1592\n",
            "Epoch 786/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0239 - val_loss: 0.1583\n",
            "Epoch 787/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0231 - val_loss: 0.1582\n",
            "Epoch 788/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0231 - val_loss: 0.1576\n",
            "Epoch 789/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0248 - val_loss: 0.1576\n",
            "Epoch 790/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0234 - val_loss: 0.1583\n",
            "Epoch 791/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0235 - val_loss: 0.1576\n",
            "Epoch 792/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0240 - val_loss: 0.1577\n",
            "Epoch 793/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0256 - val_loss: 0.1604\n",
            "Epoch 794/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0254 - val_loss: 0.1576\n",
            "Epoch 795/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0237 - val_loss: 0.1572\n",
            "Epoch 796/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0231 - val_loss: 0.1599\n",
            "Epoch 797/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0237 - val_loss: 0.1572\n",
            "Epoch 798/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0240 - val_loss: 0.1576\n",
            "Epoch 799/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0245 - val_loss: 0.1577\n",
            "Epoch 800/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0235 - val_loss: 0.1583\n",
            "Epoch 801/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0235 - val_loss: 0.1591\n",
            "Epoch 802/1000\n",
            "224/224 [==============================] - 3s 11ms/step - loss: 0.0243 - val_loss: 0.1570\n",
            "Epoch 803/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0230 - val_loss: 0.1564\n",
            "Epoch 804/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0232 - val_loss: 0.1612\n",
            "Epoch 805/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0239 - val_loss: 0.1579\n",
            "Epoch 806/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0233 - val_loss: 0.1589\n",
            "Epoch 807/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0231 - val_loss: 0.1593\n",
            "Epoch 808/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0242 - val_loss: 0.1638\n",
            "Epoch 809/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0236 - val_loss: 0.1575\n",
            "Epoch 810/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0230 - val_loss: 0.1615\n",
            "Epoch 811/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0236 - val_loss: 0.1609\n",
            "Epoch 812/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0245 - val_loss: 0.1601\n",
            "Epoch 813/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0249 - val_loss: 0.1587\n",
            "Epoch 814/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0236 - val_loss: 0.1595\n",
            "Epoch 815/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0233 - val_loss: 0.1582\n",
            "Epoch 816/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0239 - val_loss: 0.1627\n",
            "Epoch 817/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0241 - val_loss: 0.1588\n",
            "Epoch 818/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0240 - val_loss: 0.1597\n",
            "Epoch 819/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0238 - val_loss: 0.1580\n",
            "Epoch 820/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0233 - val_loss: 0.1572\n",
            "Epoch 821/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0243 - val_loss: 0.1585\n",
            "Epoch 822/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0234 - val_loss: 0.1585\n",
            "Epoch 823/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0232 - val_loss: 0.1580\n",
            "Epoch 824/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0230 - val_loss: 0.1577\n",
            "Epoch 825/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0227 - val_loss: 0.1682\n",
            "Epoch 826/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0263 - val_loss: 0.1576\n",
            "Epoch 827/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0236 - val_loss: 0.1584\n",
            "Epoch 828/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0239 - val_loss: 0.1655\n",
            "Epoch 829/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0258 - val_loss: 0.1652\n",
            "Epoch 830/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0248 - val_loss: 0.1581\n",
            "Epoch 831/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0239 - val_loss: 0.1581\n",
            "Epoch 832/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0234 - val_loss: 0.1570\n",
            "Epoch 833/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0249 - val_loss: 0.1630\n",
            "Epoch 834/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0238 - val_loss: 0.1589\n",
            "Epoch 835/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0233 - val_loss: 0.1607\n",
            "Epoch 836/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0237 - val_loss: 0.1581\n",
            "Epoch 837/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0229 - val_loss: 0.1584\n",
            "Epoch 838/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0238 - val_loss: 0.1599\n",
            "Epoch 839/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0233 - val_loss: 0.1603\n",
            "Epoch 840/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0224 - val_loss: 0.1622\n",
            "Epoch 841/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0229 - val_loss: 0.1624\n",
            "Epoch 842/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0235 - val_loss: 0.1588\n",
            "Epoch 843/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0233 - val_loss: 0.1621\n",
            "Epoch 844/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0250 - val_loss: 0.1609\n",
            "Epoch 845/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0238 - val_loss: 0.1602\n",
            "Epoch 846/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0234 - val_loss: 0.1596\n",
            "Epoch 847/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0237 - val_loss: 0.1599\n",
            "Epoch 848/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0234 - val_loss: 0.1595\n",
            "Epoch 849/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0245 - val_loss: 0.1629\n",
            "Epoch 850/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0238 - val_loss: 0.1595\n",
            "Epoch 851/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0241 - val_loss: 0.1600\n",
            "Epoch 852/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0241 - val_loss: 0.1597\n",
            "Epoch 853/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0239 - val_loss: 0.1612\n",
            "Epoch 854/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0227 - val_loss: 0.1612\n",
            "Epoch 855/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0227 - val_loss: 0.1618\n",
            "Epoch 856/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0247 - val_loss: 0.1603\n",
            "Epoch 857/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0236 - val_loss: 0.1659\n",
            "Epoch 858/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0254 - val_loss: 0.1639\n",
            "Epoch 859/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0241 - val_loss: 0.1607\n",
            "Epoch 860/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0233 - val_loss: 0.1609\n",
            "Epoch 861/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0227 - val_loss: 0.1586\n",
            "Epoch 862/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0226 - val_loss: 0.1617\n",
            "Epoch 863/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0229 - val_loss: 0.1601\n",
            "Epoch 864/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0232 - val_loss: 0.1614\n",
            "Epoch 865/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0231 - val_loss: 0.1611\n",
            "Epoch 866/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0231 - val_loss: 0.1583\n",
            "Epoch 867/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0231 - val_loss: 0.1637\n",
            "Epoch 868/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0228 - val_loss: 0.1620\n",
            "Epoch 869/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0230 - val_loss: 0.1645\n",
            "Epoch 870/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0233 - val_loss: 0.1625\n",
            "Epoch 871/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0244 - val_loss: 0.1628\n",
            "Epoch 872/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0244 - val_loss: 0.1608\n",
            "Epoch 873/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0235 - val_loss: 0.1590\n",
            "Epoch 874/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0233 - val_loss: 0.1592\n",
            "Epoch 875/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0228 - val_loss: 0.1621\n",
            "Epoch 876/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0240 - val_loss: 0.1620\n",
            "Epoch 877/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0258 - val_loss: 0.1591\n",
            "Epoch 878/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0235 - val_loss: 0.1597\n",
            "Epoch 879/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0229 - val_loss: 0.1590\n",
            "Epoch 880/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0234 - val_loss: 0.1599\n",
            "Epoch 881/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0262 - val_loss: 0.1598\n",
            "Epoch 882/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0234 - val_loss: 0.1622\n",
            "Epoch 883/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0230 - val_loss: 0.1649\n",
            "Epoch 884/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0234 - val_loss: 0.1609\n",
            "Epoch 885/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0226 - val_loss: 0.1610\n",
            "Epoch 886/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0231 - val_loss: 0.1617\n",
            "Epoch 887/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0235 - val_loss: 0.1616\n",
            "Epoch 888/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0243 - val_loss: 0.1639\n",
            "Epoch 889/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0235 - val_loss: 0.1616\n",
            "Epoch 890/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0227 - val_loss: 0.1599\n",
            "Epoch 891/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0229 - val_loss: 0.1615\n",
            "Epoch 892/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0224 - val_loss: 0.1591\n",
            "Epoch 893/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0232 - val_loss: 0.1611\n",
            "Epoch 894/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0223 - val_loss: 0.1629\n",
            "Epoch 895/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0233 - val_loss: 0.1597\n",
            "Epoch 896/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0233 - val_loss: 0.1611\n",
            "Epoch 897/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0225 - val_loss: 0.1652\n",
            "Epoch 898/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0251 - val_loss: 0.1638\n",
            "Epoch 899/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0226 - val_loss: 0.1631\n",
            "Epoch 900/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0222 - val_loss: 0.1631\n",
            "Epoch 901/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0227 - val_loss: 0.1607\n",
            "Epoch 902/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0230 - val_loss: 0.1614\n",
            "Epoch 903/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0238 - val_loss: 0.1634\n",
            "Epoch 904/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0231 - val_loss: 0.1614\n",
            "Epoch 905/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0232 - val_loss: 0.1613\n",
            "Epoch 906/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0233 - val_loss: 0.1617\n",
            "Epoch 907/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0226 - val_loss: 0.1625\n",
            "Epoch 908/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0232 - val_loss: 0.1638\n",
            "Epoch 909/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0227 - val_loss: 0.1636\n",
            "Epoch 910/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0224 - val_loss: 0.1593\n",
            "Epoch 911/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0225 - val_loss: 0.1644\n",
            "Epoch 912/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0232 - val_loss: 0.1604\n",
            "Epoch 913/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0222 - val_loss: 0.1630\n",
            "Epoch 914/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0242 - val_loss: 0.1616\n",
            "Epoch 915/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0229 - val_loss: 0.1640\n",
            "Epoch 916/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0228 - val_loss: 0.1603\n",
            "Epoch 917/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0226 - val_loss: 0.1617\n",
            "Epoch 918/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0229 - val_loss: 0.1618\n",
            "Epoch 919/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0227 - val_loss: 0.1637\n",
            "Epoch 920/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0227 - val_loss: 0.1589\n",
            "Epoch 921/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0225 - val_loss: 0.1627\n",
            "Epoch 922/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0226 - val_loss: 0.1622\n",
            "Epoch 923/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0215 - val_loss: 0.1615\n",
            "Epoch 924/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0224 - val_loss: 0.1643\n",
            "Epoch 925/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0223 - val_loss: 0.1635\n",
            "Epoch 926/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0219 - val_loss: 0.1632\n",
            "Epoch 927/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0245 - val_loss: 0.1668\n",
            "Epoch 928/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0222 - val_loss: 0.1620\n",
            "Epoch 929/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0224 - val_loss: 0.1633\n",
            "Epoch 930/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0226 - val_loss: 0.1641\n",
            "Epoch 931/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0226 - val_loss: 0.1628\n",
            "Epoch 932/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0225 - val_loss: 0.1624\n",
            "Epoch 933/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0225 - val_loss: 0.1649\n",
            "Epoch 934/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0222 - val_loss: 0.1626\n",
            "Epoch 935/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0216 - val_loss: 0.1638\n",
            "Epoch 936/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0227 - val_loss: 0.1616\n",
            "Epoch 937/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0223 - val_loss: 0.1638\n",
            "Epoch 938/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0223 - val_loss: 0.1665\n",
            "Epoch 939/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0229 - val_loss: 0.1628\n",
            "Epoch 940/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0222 - val_loss: 0.1655\n",
            "Epoch 941/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0226 - val_loss: 0.1654\n",
            "Epoch 942/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0231 - val_loss: 0.1639\n",
            "Epoch 943/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0235 - val_loss: 0.1612\n",
            "Epoch 944/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0224 - val_loss: 0.1648\n",
            "Epoch 945/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0233 - val_loss: 0.1660\n",
            "Epoch 946/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0220 - val_loss: 0.1629\n",
            "Epoch 947/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0227 - val_loss: 0.1643\n",
            "Epoch 948/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0229 - val_loss: 0.1615\n",
            "Epoch 949/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0224 - val_loss: 0.1675\n",
            "Epoch 950/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0230 - val_loss: 0.1625\n",
            "Epoch 951/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0223 - val_loss: 0.1660\n",
            "Epoch 952/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0224 - val_loss: 0.1617\n",
            "Epoch 953/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0216 - val_loss: 0.1644\n",
            "Epoch 954/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0224 - val_loss: 0.1635\n",
            "Epoch 955/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0228 - val_loss: 0.1643\n",
            "Epoch 956/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0216 - val_loss: 0.1629\n",
            "Epoch 957/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0227 - val_loss: 0.1681\n",
            "Epoch 958/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0238 - val_loss: 0.1660\n",
            "Epoch 959/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0221 - val_loss: 0.1623\n",
            "Epoch 960/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0230 - val_loss: 0.1632\n",
            "Epoch 961/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0225 - val_loss: 0.1597\n",
            "Epoch 962/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0224 - val_loss: 0.1652\n",
            "Epoch 963/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0236 - val_loss: 0.1637\n",
            "Epoch 964/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0221 - val_loss: 0.1624\n",
            "Epoch 965/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0230 - val_loss: 0.1613\n",
            "Epoch 966/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0214 - val_loss: 0.1638\n",
            "Epoch 967/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0224 - val_loss: 0.1646\n",
            "Epoch 968/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0222 - val_loss: 0.1620\n",
            "Epoch 969/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0222 - val_loss: 0.1646\n",
            "Epoch 970/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0227 - val_loss: 0.1621\n",
            "Epoch 971/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0222 - val_loss: 0.1648\n",
            "Epoch 972/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0218 - val_loss: 0.1661\n",
            "Epoch 973/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0223 - val_loss: 0.1660\n",
            "Epoch 974/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0223 - val_loss: 0.1641\n",
            "Epoch 975/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0229 - val_loss: 0.1658\n",
            "Epoch 976/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0219 - val_loss: 0.1658\n",
            "Epoch 977/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0228 - val_loss: 0.1647\n",
            "Epoch 978/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0220 - val_loss: 0.1649\n",
            "Epoch 979/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0224 - val_loss: 0.1645\n",
            "Epoch 980/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0216 - val_loss: 0.1658\n",
            "Epoch 981/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0223 - val_loss: 0.1656\n",
            "Epoch 982/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0217 - val_loss: 0.1641\n",
            "Epoch 983/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0219 - val_loss: 0.1637\n",
            "Epoch 984/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0218 - val_loss: 0.1669\n",
            "Epoch 985/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0217 - val_loss: 0.1705\n",
            "Epoch 986/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0233 - val_loss: 0.1641\n",
            "Epoch 987/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0220 - val_loss: 0.1679\n",
            "Epoch 988/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0227 - val_loss: 0.1654\n",
            "Epoch 989/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0225 - val_loss: 0.1647\n",
            "Epoch 990/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0237 - val_loss: 0.1650\n",
            "Epoch 991/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0223 - val_loss: 0.1660\n",
            "Epoch 992/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0221 - val_loss: 0.1637\n",
            "Epoch 993/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0214 - val_loss: 0.1646\n",
            "Epoch 994/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0222 - val_loss: 0.1635\n",
            "Epoch 995/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0213 - val_loss: 0.1627\n",
            "Epoch 996/1000\n",
            "224/224 [==============================] - 3s 12ms/step - loss: 0.0219 - val_loss: 0.1663\n",
            "Epoch 997/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0235 - val_loss: 0.1664\n",
            "Epoch 998/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0216 - val_loss: 0.1671\n",
            "Epoch 999/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0221 - val_loss: 0.1685\n",
            "Epoch 1000/1000\n",
            "224/224 [==============================] - 3s 13ms/step - loss: 0.0230 - val_loss: 0.1686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l39CJN1Pk43I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "022dae36-57af-4580-fca2-2304d29b7b2b"
      },
      "source": [
        "plt.plot(h.history['loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.show()"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr1cx3mMrp5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83f93813-56ed-4f57-ded7-7b9bfaebae28"
      },
      "source": [
        "\n",
        "encoder_model = Model(encoder_inputs,encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h,decoder_state_input_c]\n",
        "decoder_outputs,state_h,state_c = decoder_lstm(\n",
        "        decoder_inputs,initial_state = decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h,state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states\n",
        ")\n",
        "encoder_model.save('encoder.h5')\n",
        "decoder_model.save('decoder.h5')\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_dec_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, char2int['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = int2char[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_dec_len):\n",
        "            stop_condition = True\n",
        "            \n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_dec_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "for seq_index in range(20):\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Wrong sentence:', input_texts[seq_index])\n",
        "    print('Corrected sentence:', decoded_sentence)\n",
        "    print('Ground Truth:',target_texts[seq_index])"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "-\n",
            "Wrong sentence: نتنزحر\n",
            "Corrected sentence: نتناحر\n",
            "\n",
            "Ground Truth: \tنتناحر\n",
            "\n",
            "-\n",
            "Wrong sentence: وقتلوه\n",
            "Corrected sentence: وقتلوه\n",
            "\n",
            "Ground Truth: \tوقتلوه\n",
            "\n",
            "-\n",
            "Wrong sentence: سجنوه\n",
            "Corrected sentence: سجنوه\n",
            "\n",
            "Ground Truth: \tسجنوه\n",
            "\n",
            "-\n",
            "Wrong sentence: أر؟لته\n",
            "Corrected sentence: أرسلته\n",
            "\n",
            "Ground Truth: \tأرسلته\n",
            "\n",
            "-\n",
            "Wrong sentence: بتوسلات\n",
            "Corrected sentence: بتوسلات\n",
            "\n",
            "Ground Truth: \tبتوسلات\n",
            "\n",
            "-\n",
            "Wrong sentence: يصون8وا\n",
            "Corrected sentence: يصونوا\n",
            "\n",
            "Ground Truth: \tيصونوا\n",
            "\n",
            "-\n",
            "Wrong sentence: فرض\n",
            "Corrected sentence: فرض\n",
            "\n",
            "Ground Truth: \tفرض\n",
            "\n",
            "-\n",
            "Wrong sentence: الصهيونيون\n",
            "Corrected sentence: الصهيونيون\n",
            "\n",
            "Ground Truth: \tالصهيونيون\n",
            "\n",
            "-\n",
            "Wrong sentence: إنصاتهدم\n",
            "Corrected sentence: إنصاتهم\n",
            "\n",
            "Ground Truth: \tإنصاتهم\n",
            "\n",
            "-\n",
            "Wrong sentence: وتنظياته\n",
            "Corrected sentence: وتنظيماته\n",
            "\n",
            "Ground Truth: \tوتنظيماته\n",
            "\n",
            "-\n",
            "Wrong sentence: يقوى\n",
            "Corrected sentence: يقوى\n",
            "\n",
            "Ground Truth: \tيقوى\n",
            "\n",
            "-\n",
            "Wrong sentence: يجرحون\n",
            "Corrected sentence: يجرحون\n",
            "\n",
            "Ground Truth: \tيجرحون\n",
            "\n",
            "-\n",
            "Wrong sentence: التفاخر\n",
            "Corrected sentence: التفاخر\n",
            "\n",
            "Ground Truth: \tالتفاخر\n",
            "\n",
            "-\n",
            "Wrong sentence: لمتطلبات\n",
            "Corrected sentence: لمتطلبات\n",
            "\n",
            "Ground Truth: \tلمتطلبات\n",
            "\n",
            "-\n",
            "Wrong sentence: يسألونكتم\n",
            "Corrected sentence: يسألونكم\n",
            "\n",
            "Ground Truth: \tيسألونكم\n",
            "\n",
            "-\n",
            "Wrong sentence: غباؤم\n",
            "Corrected sentence: غباؤكم\n",
            "\n",
            "Ground Truth: \tغباؤكم\n",
            "\n",
            "-\n",
            "Wrong sentence: القدم\n",
            "Corrected sentence: القدم\n",
            "\n",
            "Ground Truth: \tالقدم\n",
            "\n",
            "-\n",
            "Wrong sentence: هاي\n",
            "Corrected sentence: هاي\n",
            "\n",
            "Ground Truth: \tهاي\n",
            "\n",
            "-\n",
            "Wrong sentence: ليشغلوا\n",
            "Corrected sentence: ليشغلوا\n",
            "\n",
            "Ground Truth: \tليشغلوا\n",
            "\n",
            "-\n",
            "Wrong sentence: ويحاول7ا\n",
            "Corrected sentence: ويحاولوا\n",
            "\n",
            "Ground Truth: \tويحاولوا\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuixlV2zZf8b",
        "outputId": "17dfb2ba-2e76-4640-913a-5a05fd86c633"
      },
      "source": [
        "encoder_input_data"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37iIIStIfQPV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}